
This is the "README.data" file for overpass Slackware package.

IMPOTRANT: This is work in progress, may also have inacurate information.
WARNING: Database initialization can be time consuming process.

The "data" is the subject in this file; the data inside the overpass database.
Here you will find the source; where and what to get for your database, the
destination for it (where to store it), how to initial the database with that data
and finally how to make it available for use on your machine (setup). The
data is OpenStreetMap (OSM) data.

Terminology:  meta, attic and change-set.

Meta: extra information such as objects versions, timestamps (create, change)
and the editing user information (ids and other things). Data files with "meta"
can have full or partial extra information.

Attic: attic data is historical data, things change, street names even city name
can change (Bombay to Mumbai, India), other things may change in the database.
Quoting from overpassAPI installation: "Since Overpass API v0.7.50, it is possible
to also retain previous object versions, the so called attic versions, in the
database. Previous object versions are accessible via [date:...], [diff:...],
[adiff:...] as well as some filters like (changed:...)." end quote.

Change-set: Objects have tags which might changed or new tag gets added, the
changes in current release OSM file from the previous release is the change-set.
Change-sets files are small and can be used to updated previous OSM file and
databases with OSM data.
The change-set is between two immediate releases. If your OSM file has three
releases since you downloaded, you need all three change-sets to update it to
the current release.

Populate (initial) database in 2 different ways:
The first is to use the "download_clone.sh" script provided with overpassAPI
source (find it in /usr/local/bin if you install using my SlackBuild script).
I have not tried this method, I do not mean to bash the script and I do really
appreciate that it is available. The script is easy way to clone the WHOLE
database from the server, no partial option. You may choose without attic or
meta data, but you still get the whole planet data.
I do not know the acctual size of the database - has to be in the 100s of GBs.
I do know that I do not have the hard disk space on my machine for it. I also
do not want to guess how long it will take to download or think of how to ensure
the integrity of the data. Please see the complete installation page (in the html
directory of the package) for "download_clone.sh" usage. If you have the hard
disk space and good (fast) internet connection then this is the way to take.

The second method to initial the database is from data file from OpenStreetMap.
We use this method to save hard disk space, I do not have one terabyte free.
The OSM data file can be for planet or smaller areas. They are available for
regions divided by countries, continents or even smaller areas like cities.
This is the method I chose for myself and describe here. You have total control
of what to include in your database.
Warning: this process can take a long time.

OSM data files formats:

The data used in overpass database is "Open Street Maps" data, the same data
used to draw the map. OSM data files tend to be huge resulting in big database.
OSM data files come in different types, overpass requires the file to initial
the database to be OSM XML bzip2-compressed format - ends with suffix .bz2.
Your source file may not be available in this format, do not worry you can
convert it to this required format.
The OSM "osmium command line tool" is used to convert between file types among
other functions on OSM files. I have a SlackBuild script for the tool on my
repository that you may need:

https://github.com/waelhammoudeh/osmium-tool_slackbuild

With osmium you may download a file with say "PBF" format then convert it to
bz2 format. For example this was exactly what I did, my source was in "pbf" and
I had to convert it with the following command:

 $ osmium cat arizona-internal.osh.pbf -o arizona-internal.osh.bz2

note that -o switch specifies output file name and from its suffix "osmium"
will figure out the format for output. See the man page for osmium. This
operation can take some time depending on file size, processor and amount
of memory on the machine. Mine run for about 10 minutes to finish.
Another note; YOU NEED THE HISTORY FILE TO HAVE ATTIC DATA
".osh.bz2".Just make sure the file format is compressed bz2.

OSM data files may or may not include "META" data (see Terminology above). Yes
you can save disk space without meta data, but your query results will not be
accurate, I would also argue that the query result is wrong. In short meta data
can include essential information. You can query overpass using other programs
such as JSOM; which requires meta data.
As for the attic data - previous objects and history - those enable more query
functions, or the lack of them disables those extra functions if you well. We
do not want to comprmise on this, I may limit the area to save disk space but I
still want full query functions.
In short choose a data file with attic (history) and meta data.

Internet sites for data files:

There are a lot of websites that provide OSM data files (or extracts), they are
not all the same in terms of organization and ease of use. One website I found
and recommand is this one: { https://download.geofabrik.de/ } for those reasons:

Simple UI with continent, regional and country files.
Map in upper-right corner
file size listing with full meta and attic data, provide changesets
osh vs osm : historical (attic) data.
(read technical details page on the site).

Please note that this site has two servers with two sets of files! You need to
have an account with OpenStreetMap to get to the server with the complete
data files. So please first register with OpenStreetMap and then start with
this URL:

        {  https://osm-internal.download.geofabrik.de/index.html  }

to choose your data file for your country or region to download.

Check this wiki page for more info about extracts and data types URL:

 { https://wiki.openstreetmap.org/wiki/Planet.osm }

Pay attention to the file size you choose, that size is NOT for your database!
It is obviously related to your final database size. My original download size
for "arizona-internal.osh.pbf" was about 319 MB, when converted to bz2
"arizona-internal.osh.bz2" it got bigger to 521 MB and my database after I
did the initialization was 19 GB with meta data and 33 GB with attic data.
Do not rush me! Meta and attic are coming down below :)

Before you download a file, read the description for the file on the website.
You need your file to have meta data and history. Also check how often files
are released. Some sites may offer change-set release and some do not. Is that
important to you?

Database home - storage:

Where you store the database is the overpass user home directory we used when
we created the overpass group and user. If you need to make any changes to that,
now is the time before you initial the database.

At this point you need to decide where to store the database. Store the database
on SSD (Solid State Drive) if you have one, or your fast hard drive, the faster
the drive the less time for the query result since there will be a lot of file I/O.
You need to make sure you have enough space for the database. I can not tell
you how much since it depends on your file and data files vary wildly in size for
countries and regions, hence it is hard to tell the required disk space.

Here are few numbers I have that may help:

  file name                    file size      Database size (attic)
-----------------------------------------------------------------------------
arizona-internal.osh.bz2        521 MB         33 GB
us-west-internal.osh.bz2        6266 MB        95 GB

That database size was the final size, during the initial step you need TWICE of
that size of free disk space!
Also keep in mind files in the above table were originally in .pbf format with
initial sizes of 318 MB and 4075 MB respectively.
I recommand at least 70 GB free disk space for small (about 500 MB) data
file source.

Before leaving this section, I am going to make two assumptions as follow:

   1-  Store database under "/home" directory since there is enough disk space,
        or our full path for database destination is: { /home/overpass }
   2- The input file I will use has meta and attic data with the name "infile.osh.bz2"


Initial The Database:

With the above assumptions we initial the data base using "init_osm3s.sh" script
which is provided by the overpassAPI, the script is a frontend to the program
"update_database". If you used my SlackBuild to install overpassAPI then you
can find both under "/usr/local/bin" directory.

"init_osm3s.sh" usage is as follows:

        init_osm3s.sh inputfile $DBDIR $EXECDIR [option]

the arguments are:

    inputfile: the input file to use, must be in "bz2" format
    $DBDIR: the database destination directory
    $EXEDIR: the path to "bin" directory entry where "update_database" can be
    found.

    option is one of:
        empty - nothing --> database without meta data.
        --meta --> database with meta data
        --keep-attic --> database with meta data plus attic data

There is another option for "--compression-method" which is not documented!
Nothing is documented really, I have not used this option.
Also "update_database" takes another option [--map-compression-method=?] I did
not use this option either.

Now you can see the assumptions I made above, I hope. For us the arguments are:

    inputfile --> "infile.osh.bz2"
    $DBDIR --> /home/overpass
    $EXECDIR --> /usr/local/
    option --> [--meta]  and [--keep-attic]. More about those down.

The same input file can be used with all options - our input file has attic data.
When the "option" is left empty, you get a basic database with no meta data nor
attic data. This is the smallest database from that input file - in terms of disk
space. In my opinion this a crippled database and I would not use this option.
The [--keep-attic] option will result in full (largest) database from the same
input file. It will also be the slowest - in terms of query result speed.
The [--meta] option is in middle of the two - in terms of disk space and query
speed too.

Please do not try to run anything as root, this applies also to initialling the
database. This was the whole reason for creating "overpass" user and group.

Do the following to initial data base:
   - As root user change user to overpass with:
     root@lazyant:~# su overpass <enter>

   - Then your prompt should look like this on your terminal:
     overpass@lazyant:/root$

     And whoami and its output should look like:
     overpass@lazyant:/root$ whoami
     overpass

     Assuming everything is good; change directory to where you placed your
     "infile.osm.bz2" and initial the data base with:

     overpass@lazyant:/root$ nohup /usr/local/bin/init_osm3s.sh infile.osm.bz2 "home/overpass/" "/usr/local/" --meta &

Or if you want attic data in your database (change [--meta] to [--keep-attic]) as follows:

    overpass@lazyant:/root$ nohup /usr/local/bin/init_osm3s.sh infile.osm.bz2 "home/overpass/" "/usr/local/" --keep-attic &

This step is time consuming depending on a lot of factors: input file size, processor
speed, memory, type of hard disk.


[TO BE CONTINUED]

TO DO:
add time info for init_osm3s.sh
setup rc.dispatcher ...



   $ /usr/local/bin/init_osm3s.sh inputfile.bz2 "/home/overpass/" "/usr/local/" --meta &


   Do the following to initial data base:
   - As root user change user to overpass with:
     root@lazyant:~# su overpass <enter>

   - Then your prompt should look like this on your terminal:
     overpass@lazyant:/root$

     And whoami and its output should look like:
     overpass@lazyant:/root$ whoami
     overpass

     Assuming everything is good; change directory to where you placed your
     "infile.osm.bz2" and initial the data base with:

     overpass@lazyant:/root$ nohup /usr/local/bin/init_osm3s.sh infile.osm.bz2 "{DB_ROOT}/overpass/" "/usr/local/" --meta &

     You need full path for the script: /usr/local/bin/init_osm3s.sh above.
     Replace {DB_ROOT} above with your real path.

     My actual infile.osm.bz2 was "arizona-latest-internal.osm.bz2" for the
     state of Arizona with file size about 300 MB, on my machine the above
     command to initial the data base took about 32 minutes, with directory
     size about about 19 GB. YMMV! (Was 17 GB for source data file from 2 years ago)

   With those steps so far, you can query your data base on the command line.
   Using the example file provided with this README; and please replace with
   good points from your database input file:

     $ osm3s_query --db-dir={DB_ROOT}/overpass < example

   above assumes you are in the directory where the example file is.

Data base updates will not be covered here. See documentation in your
installation for that, or check online :)

Dispatcher has modes related to meta, no meta and attic .....
The "dispatcher" program is part of the overpass package, it is the daemon
which forwards queries to the correct part of the package. As long as the
dispatcher is running, your queries to overpass will be answered.
